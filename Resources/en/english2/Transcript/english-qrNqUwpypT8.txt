design of fake Mews Detection System. - Okay, sounds good. So I'm gonna talk a little bit about my assumptions about the system. I will assume that we will be designing a fake news detection system for social media because increasingly news are read both through social networks. Although some of the components of the system gonna talk about are applicable to pure text applications
have any social network information. I will also assume that we have access to information about the social network. So users, user full accounts, how the information flows through the network, like posts, timing of the posts, et cetera, et cetera. So I will share my screen and show you a diagram of the fake news detection system. So we're going to have a few modules in this, in this.
fake news detection system. We are going to assume that we have an incoming media post. This is going to be our input and our output is going to be whether it's fake or real and there's going to be obviously some action taken depending on that. In the beginning we want to classify whether this is news or not news because if we stick a label of fake on a someone's opinions, opinions we might have some problems arising from that.
So we will have some attributes that come with together with the social media posts. So basically we determine whether it's not news. Then whether it has a URL or not URL, and then we have the user characteristics, maybe number of followers, connections, other posts, etc. And then we will have three different modules where this social media posts will go into. The first.
The first one is a text analysis module. The second one will analyze the URL, if it exists, and the third one will analyze the movements of the post through the network. So the text analysis module will do two things. It will have a model for analyzing just a text, and there are some features that might give out fake news posts.
For example, it might be very subjective, it might have a lot of question marks, some quantifiers, generalizations. And that kind of analysis is good, but it's probably not very reliable because as we know, even people are very bad at determining whether new species fake or real. So the machine probably will not be either. So to support that, we will have another
part of this module where we represent each fact as an RDF triple. So this is just saying, for instance, we have a sentence, "John saw the cat." So we represent that as a triple where the subject is John, the predicate is saw and the object is the cat. And we take more complex sentences and we'll represent each pairing of subject and object with the predicate.
as a triple. And then basically for this one to work, we need an outside knowledge base, such as a DBpedia. Because then we match these facts to DBpedia. And then recent research has found that the more concrete those entities and those facts and those triples are, the better the chance that the new species is real.
Because if it's very general, then it's easy to go either way. You can be talking about something very confidently, but it's just just talk. So-- Yeah. Yeah, so combining these two things, and there are different options for combining these. We could train two different models, one for the text alone, one for the effects of triples. We could combine the two and use embedded.
and concatenate, for example, the embeddings. And then, or we could have a voting system, there are many different options for this. And if I did voting, I would put less weight on the text only and more weight on the fact as triple's analysis because it's also supported by an outside source that we know is verified. - Got it. - So this will output with a fake or real. So, and then we, we,
we will have some confidence marker. And if it's high confidence, then probably we will want to take immediate action. If it's definitely a fake news item. But if it's low confidence, then we will defer to our third module, which I'll talk about later. So the second module will take the URL. It will take the URL, it will read the URL. And then it will take the title.
of the text and the text itself. And also, you are well, is this a URL of the actual post itself or is this a URL contained within the post? Yeah, so I should have been more clear. It's the URL of that's contained in the post. Got it. Okay. So we take that supporting URL for the social media post and then we take the title and We take the text and again, recent research
has found that if the title and the text agree, then it's more likely to be a real news item. But if they don't agree, then probably it's either fake or misleading, it's like clickbait, because the headline can say one thing, but the actual text is not saying that. So that's called stance detection, and then we will do that using this module. And then we'll
And we will do the same thing. And I am actually thinking that probably these three, just text, faxes, ripples, and URL could be combined into one module that will say whether it's fake or real. So if it's high confidence, take action, if it's low confidence, we go on to the network analysis module. And why- Yes, it's a you mentioned that these two could be combined into one or two.
are there any advantages to separating them into two separate modules? Yes, because some posts will not contain a URL. So-- That's fair. OK. But we can-- there are probably ways around that, so-- but yeah. That's fair. And the reason why we have the network analysis module that's kind of to the side, and we only use it with low confidence scores, is because it can only work.
work if it's delayed in time because it is analyzing the movement of the posts through the network. Basically how the users are posting, which users are posting, etc., etc. So about in the recent research that I read, it said about two hours is the time that needs to pass before this module can work correctly and identify.
whether the item is real or fake. And we will need a model here as well that takes in apart from the actual post and the user information of the post, the user who posted the item, we need the representation of the social network as a graph database. And obviously we will need to partition it because we cannot probably put in the whole thing
in there. Yeah. And water, yeah, if you're touching on this, I apologize. What are some of the characteristics that a fake news post would demonstrate in its movement in the network versus real news? So I think it might be different, which users are posting it and how quickly it's
appearing through the network, because some people might be copy-pasting. If it's like robots, it's moving very fast, but it might be not real people who are disseminating it, for example. So that's one characteristic, for example. So here, I think if we take all the combination of all these and it says it's fake, then we
confidence that it's really fake. So take some action based on this output. Okay. So the two external data sources that we will need are the knowledge base that is put in for the facts analysis and the representation of the social network. And we will need machine learning models. And these two will need to be updated frequently.
as the facts change quickly and then social networks changes. And how frequently that will need to be decided, depending on the business requirements, I would say daily, but maybe even more frequent than that. I don't know. - Okay, that's fair. - Yeah. And then these will require machine learning models and to train such machine learning models, we will obviously need some training data
And there are the data sets out there that are available for training. For instance, there is the layer data set that's about 13,000 short statements, which is fake or real, just text. And then there is also FNC1, which is about 75,000 labeled headlines and articles. So this would be for the stance detection, the correspondent of our team.
headline and document. >> We're very. >> Yeah. And then once this system, we put it into production, we will definitely need to have some quality assurance that it's working as expected and I'm expecting that we would need to do daily checks of all three models or for depending on how you count here. Daily checks on all three models to evaluate whether they're
they're actually doing their jobs and how accurately they're giving us the answers? Yes. Or how often they're getting us the right answer rather? Yeah, just measuring, you know, precision and recall and those metrics will also depend on which metrics we optimize for will depend whether this system is completely automated or if there is a human in the loop, right? If there's a human in the loop, we can have high recall and precision
can be a little less because we want to cover all the cases and the human can hopefully sort through the rest. Yeah, yeah. Okay, that's fair. And what do you do in the situations where let's say you get a lot of false positives for fake news? What is the approach in this system to be able to deal with sorting those false positives ultimately? Well, I think the first thing is to do some air analysis just to figure out what happened
why are we having so many false positives? Maybe people are talking about this one particular topic and that's being labeled as false positive and then we need to update the model somehow to make sure that they are not going through as fake when they're actually real. - Got it, okay. I'm interested in your perspective on if you were approaching this from the bad actor standpoint,
ways that someone could break this system or take advantage of it? Interesting. I guess that's a good way to make sure that it actually works. Well, I think a lot of social media users, they figure out very quickly how the algorithm works, and they try to gain the system. I mean, even I know on LinkedIn, if you post a post with a link, hit will never reach any kind of.
of viewership, there is going to be very low. So people post links in the comments. Same thing. People figure out, oh, the URLs are not going through. I'm just going to put it in the comments. And yeah, this is something that's kind of a cat and mouse game where we try to build a system that will protect us from bad actors and the back of actors figure it out and now we have to go back and do something else.
Yeah, yeah, that's better. This is a great start to building this kind of system. Thank you so much, Jenya. I'm wondering, do you have any thoughts on, if someone encounters a question like this in the wild, what are your suggestions for how to approach it? Because it's a pretty broad question and you could go in so many different directions for it. So what are your thoughts on that? - Well, I think when you think of any kind of project like this where there's NLP or a machine learning involved, think about the business.
the requirements and how they translate into what you need to do and how you find the training data whether the training data will correspond to what's out there because the, for instance, the data sets that are public, they go still very quickly. They might be very curated while your data is going to be wildly different. So you're, you know, so maybe a data set that's out there is good for a proof of value, but then you will need to collect your own. How are you going to collect your your own data.
And then after you make the models and they seem to work, how are you going to monitor them and make sure that they don't fail on you, especially silently. Yeah. Lovely. Thank you so much, Danielle. Any final thoughts before we wrap up? Thank you. I enjoyed answering the question and hope for you enjoyed watching it. Yeah, absolutely. I learned something during this. So it's not my area of expertise, but I really
enjoyed learning about how you would build a system like this for a very, very tough and pertinent problem today. So thank you so much. And I know this is valuable for everyone at home. Good luck with your interviews. Thanks so much for watching. Don't forget to hit the like and subscribe buttons below to let us know that this video is valuable for you. And of course, check out hundreds more videos just like this at try exponent dot com. Thanks for watching and good luck on your upcoming interview.
