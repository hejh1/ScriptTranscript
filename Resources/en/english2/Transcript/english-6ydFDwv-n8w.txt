I've been covering this industry a long time, and there is always some new, new thing that Big Tech is chasing. First, it was self-driving cars, and then it was the metaverse. And now everyone is all in on AI. There's one Big Tech giant that's made it clear. It's not missing out. So welcome to Microsoft headquarters in Redmond, Washington, where they have made a massive investment in Open AI. They are already off to the races, integrating this new technology.
but winning is a totally different story. I'm about to go talk to Microsoft's CEO, Satya Nadella about why he thinks he can do it. - Thank you for coming. - And I haven't seen you in person in so long. - I know it's been ages. - Microsoft is a household name that totally revolutionized how we work over 30 years ago. Windows, Word, Excel, PowerPoint. these products turn the software maker into a
Bahimuth put the big in big tech and made Microsoft's co-founder Bill Gates and its next CEO Steve Balmer billionaires. But in the 90s, the US government accused Microsoft of being a monopoly and then the company settled a massive antitrust suit. For over a decade, Microsoft stock flatlined. Then came Satya Nadella, the guy Microsoft hoped would make the company cool again. This company has three CEOs. They're all right here. This is all.
Nadella resurrected Microsoft as a power player in the market for business software and cloud computing, then positioned it at the forefront of the AI revolution, largely thanks to a massive investment in OpenAI. Microsoft is now OpenAI's main commercial partner, trading powerful servers and billions of dollars for access to chat GPT, sparking new life into old products, especially their languishing search engine.
it's hiccups. We'll talk to OpenAIC EOS Amalman in a moment. But first, this new AI chatbot is helping Satya in some surprising ways. Have you been playing around with it a lot? Like fun stuff, discovery? I am super verbose and polite now in email responses. It's watching, Leigh-Ey is always watching. It is fun like the guy who leads our office team.
and I was responding to him. And he was like, what is this man? He was like, sort of so pleasant.  Yeah, it's sort of very habit forming in the sense that once you get used to having chat, even if I'm using it one, because there's a lot of times I'm just navigating, using such as a navigational tool. But once you get used to it, you kind of feel like I have got to have these rails. Microsoft has been working on AI for decades. And chat plots actually aren't anything new. but all of a sudden everyone
is salivating. Why do you think the moment for AI is now? AI has been here, in fact, it's mainstream, right? I mean, search is an AI product, even the current generation of search. Every news aggregation, recommendation, and YouTube, or e-commerce, or TikTok, or all AI products. Except they're all, I would say, today's generation of AI is all autopilot. In fact, it's a black box that is dick-
dating in fact how our attention is focused, whereas going forward, the thing that's most exciting about this generation of AI is perhaps we move from autopilot to copilot where we actually probbed it. - How transformative a change do you think this will be in how we work? - I think the probably the biggest difference maker will be business chat because if you think about the most important database in any company is the database underneath all of your productivity software.
is all silo today. But now I can say, oh, I'm going to meet this customer. Can you tell me the last time I met them? Can you bring up all the documents that are written up about this customer and summarize it so that I'm current on what I need to be prepped for? - How do you make sure it's not Clippy 2.0? That it is helpful. Delightful. Doesn't want to make me click out ASAP. - Once they're under my control, the entire world will be subject to my whims. Go where you paperclip.
They're two sets of things. One is, you know-- You're laughing because-- You're because, look, our industry is full of lots of examples from clippy to even let's say, current generation of these assistants and so on. They're all a brittle. I think we are also going to have to learn that, ultimately, these are tools. Just like any time somebody sends me a draft, I review the draft. I just don't accept the draft. We will do that. In 1995, Bill Gates sent a memo calling the internet a tidal way.
if that would change all the rules and was gonna be crucial to every part of the business. Is AI that big? - Yeah, I mean, in fact, I sort of say the chat GPT when it first came out was like when music first came out, I think in 1993. And so yes, it does feel like, you know, to the Bill memo in 1995. It does feel like that to me. - So it's as big as the internet. - I think it's as big. It's just like in all of these things, right? We in the tech industry or, you know, classic experts at overhyp
everything. I hope, at least that what motivates me is I want to use this technology to truly do what I think at least all of us are in tech for which is democratizing access to it. How much market charity do you think you can really take from Google? Like, protection, prediction, give me a 30-year notch. Look, we are a real, I'm thrilled to be in search. We're a very small player in search and I look forward to every inch we gain is a big gain.
You're coming for search. They're coming for office. They're now putting AI in their Google Docs, Cheats, and Gmail. Are we just going to see you and Sundar trying to one up each other every weekend as race to AI greatness? I mean, look, at the end of the day, the fun part of being in this industry and competing is the innovation. And competition is the last time I checked a fantastic thing for users and the industry. And I think Google is going to do--
a very innovative company and we have a lot of respect for them and I expect us to compete in multiple categories. Microsoft just reportedly laid off a team focused on ethical and responsible AI. Meantime you've got the Center for Humane Technology calling the Race to AI a Race to Recklessness. How do you respond to that? This is no longer a side thing for Microsoft, right? Because in some sense, whether it's design, whether it's alignment, safety, ethics, it's kind of like saying quality performance.
and design, core design. So I can't have now an AI team on the side. It's all being mainstream. And then I think, if anything, debate, dialogue, and scrutiny on what is this space of innovation, is it really creating benefits for society? I think are absolutely, and for I'll welcome it. And in that context, let's also recognize, especially with this AI, Why would we not?
asking ourselves, like the AI that's already in our lives, and how, what is it doing? There's a lot of AI that I don't even know what it's doing and accept them happily clicking away and accepting the recommendations. So why don't we, in fact, educate ourselves to ask all of what AI is doing in our lives and then say how to do it safely and in a lined way? - I think a lot about my kids and how AI will have something that I don't, which is an infinite amount time to spend with them and how.
These chapats are so friendly and how quickly that could turn into an unhealthy relationship or you know, maybe it's nudging them to make a bad decision. It's a great point. As a parent, does any part of that scare you? That's kind of one of the reasons why I think this moving from autopilot to this co-pilot hopefully gives us more control whether it's as parents or more importantly even as children. We should of course be very, very watchful of what happens. but at the same time I think
this generation of bots and this generation of AI, probably just go from engagement to more, giving us more agency to learn. - I want to ask about jobs because obviously, Microsoft makes software that helps people do their jobs and I wonder if AI-related software will put some people out of jobs. Sam Altman has this idea that AI is going to create this kind of utopia and generate wealth that's going to be enough to cut everyone a decent size check.
What eliminate some jobs? Do you agree with that? You look up from Keynes to I guess, Altman. They've all talked about the two-day work week and I'm looking forward to it. But the point is, yes, there's going to be some changes in jobs. There's going to be some places where there will be wage pressure. There will be opportunities for increased wages because of increased productivity. We should look at it all. And at the same time, being very clear-eyed about any displacement risk. the center of a potentially
The tectonic shift in job creation is Sam Altman. He's promised that AI will create a kind of utopia when it joins the workforce, while also raising alarms about the dangers, signing his name to statements warning of the risk of extinction. For many, the upsides of AI are hard to believe. The fear that AI could take their jobs in part led to the prolonged writers and actors strike in Hollywood. The type of system, chronic type of system, that's in really right reasons.
Sorry. Over the summer, Altman traveled the world to talk about the promise and peril of AI. I caught up with him when he returned to San Francisco at Bloomberg's annual text summit.
- So you've been traveling a ton. - Yeah. - What's the like eat, sleep, meditate, yoga, attack, routine? - Um, there was like no meditation or yoga on the entire trip and almost no exercise. That was tough. I slept fine actually. - Was the goal more listening or explaining? - The goal was more listening. It ended up with more explaining than we expected. We ended up meeting like many, many world leaders and talked about the sort of the need for global regulation. and that was like more explaining.
The listen was super valuable. I came back with like 100 handwritten pages of notes. - I heard that you do handwritten notes. - I did handwritten notes. - What happens to the handwritten notes? - But in this case, like I distilled it into like here were the top 50 pieces of like feedback from my users and we need to go often to, but there's like a lot of things when you like get people in person like face to face or over a drink or whatever, where people really will just like say, you know, here is like my very harsh feedback on what you're doing wrong and what I want to be different. - You didn't go to China or Russia? I spoke remotely in China, but not Russia.
Should we be worried about them? Um. And where they are on AI? Or what they're doing here? Yeah, I would love to know more precisely where they are. That would be helpful. We have, I think, very imperfect information there. So how has chat GPT changed your own behavior? There's like a lot of, like, little ways, and then kind of, like, one big thought. The little ways are, you know, like, on this trip, for example, the translation was, like, a lifesaver.
that if I am trying to write something, which I write a lot, to remember, publish just like from my own thinking. And I find that I write faster and can think more somehow. So it's like a great unsticking tool. But then the big way is I see the path towards like this just being like my super assistant for all of my cognitive work. - Super assistant. You know, we've talked about relationships with chatbots. Did you see this is something that people could get emotionally attached to? and how do you feel about that?
I think language models in general are something that people are getting emotionally attached to. Um, and, you know, I have like a complex set of thoughts about that. I personally find it strange. I don't want it for myself. I have a lot of concerns. I don't want to be like the kind of like people that I'm not a people what they can do with tech. But it seems to me like something I need to be careful with. You've talked about how you are constantly in rooms full of people going "Holy ****." - Yeah.
- It was like very interesting to get out of the SF echo chamber, whatever you want to call it, and see the ways in which the holy  concerns were the same everywhere. And also the ways they're different. So like everywhere, people are like, the rate of change seems really fast. You know, what is this gonna do to the economy good and bad? There's change in change, rain's anxiety for people. - There's a lot of anxiety out there, there's a lot of fear. The comparisons to nuclear, the comparisons to bio-weapons.
- There is a lot of anxiety and fear, but I mean, there's like way more excitement out there. I think like with any very powerful technology, synthetic bio and nuclear, two of those AI is a third, there are major downsides we have to manage to be able to get the upsides. And with this technology, I expect the upsides to be far greater than anything we have seen and the potential downsides also, like super bad, super bad. So we do have to manage through those, by the...
of conversation about how to productively do that has gotten so much better so fast. Like, I went into the trip somewhat optimistic and I finished it super optimistic. - Yeah. So is your bunker prepped and ready to go for the AI apocalypse? - A bunker will not help anyone if there's an AI apocalypse, but I know that like, you know, journalists seem to really love that story. - I do love that story. - I wouldn't over-correct on like, boyhood survival prep. So cops go, I like this stuff. - Yeah. - It's not gonna help with AI. There's been the talk about the camera.
which the big red button. - I hope it's clear that's a joke. - It's clear to joke. Could you actually turn it off if you wanted to? - Yeah, sure. I mean, we could like shut down our data centers or whatever, but I don't think that's what people mean by it. I think what we could do instead is all of the best practices we're starting to develop on how to build this safely, the safety tests, external audits, internal external red teams, lots more stuff like the way that it would be turned off
is not the dramatic, you know, gigantic switch from the movies that cuts the power blah, blah, blah. It's that we have developed and are continuing to develop these rigorous safety practices. And that's what the kill switch actually looks like, but it's not as theatric. There is now a new competitive environment. For sure. And OpenAI is clearly the front runner. But who are you looking over your shoulder at? This is like not only a competitive environment, but I think this is probably the most competitive an environment attack right now. Sort of like looking at everybody, but.
I always, you know, given my background and startups, I directionally worry more about the people that we don't even know to look at yet, that they could come up with some really new idea to be missed. - How would you describe your relationship with Sacha Nadella, how much control they have? You know, I've heard people say, you know, Microsoft's just gonna buy OpenAI, you're just making big tech bigger. - Um, company's not for sale.  I don't know how to be more clear than that.
I think it's a, that these like big major partnerships between tech companies usually don't work. This is an example of it working really well, or like super grateful for it. - Have you talked to Elon at all behind the scenes? - Sometimes. - Mm-hmm. - What do you guys talk about? I mean, it's getting heated in the public. - Yeah.  - I mean, we talk about like a super wide variety of important and totally trivial stuff. - Why do you think he's so frustrated or kind of a, I mean, it's almost,
some attacking going on in a while. - You should ask him. - I would like to know. I'd like to better understand it. - I don't think this is in the top, like 100 most important things happening related to AI right now for what it's worth. - Is there any aspect of our lives that you think AI should never touch? - My mom always used to say, never say never, never say always. And I think that's like a generally good advice if I'd made a prediction now. I'm sure it could end up being Ron in some subtle way. I think AI is going to touch most of them.
aspects of our lives, and then there will be some parts that stay surprisingly the same. But those kind of predictions are humbling and very easy to get wrong. What do you think kids should be studying these days? Resilience, adaptability, a high rate of learning, creativity, certainly familiarity with the tools. So kids still be learning how to code? Because I've heard people say, "Don't need to learn how to code anymore." Just math, just biology. Well, I'm biased because I like coding. I think you should learn to code.
write code very much anymore, but I randomly did yesterday. But learning to code was great as a way to learn how to think. And I think coding will still be important in the future. It's just going to change a little bit or a lot. We have a new tool. What are we all going to do when we have nothing to do? I don't think we're ever going to have nothing to do. I think what we have to do may change. Like what you and I do for our jobs would not strike people from a few thousand years ago as real work. but we found new things.
to want and to do and ways to feel useful to other people and get fulfillment and create. And that will never stop. But probably, I hope you and I look, you know, if we can look at the world a few hundred years in the future, be like, wow, those people have it so good, I can't believe they call the stuff work it's so true. So we're not going to be all just laying on the beach eating bonbons. Some of us will and more power to people who want to do that. Do you think in your heart of heart that the world is going to be more fair and more equitable?
I do. I think that technology is fundamentally an equalizing force. It needs partnership from society and our institutions to get there. But if we can like my big picture, highest level, like I'll zoom all the way out, view of the next decade is that the cost of intelligence and the cost of energy come way, way down. And if those two things happen, it helps everyone, which is great. But I think it lifts up the floor a lot. So where do you want to take open AI next?
making better and better, more capable models, and make them available more widely and less expensive. - What about the field of AI in general? - There's many people working on this, so we don't get to take the field anywhere, but we're pretty happy with our contribution. Like we think we have nudged the field in a way that we're proud of, so we're working on new things too. - One of the new things. - They're still in progress. - Is there room for startups in this? - Totally. I mean, we were a startup not very long ago. - But you're almost already in incumbent. Of course, but when we see
started, like, you could have asked the same question. In fact, people did. In fact, I myself wondered, like, is it possible to take on Google in DeepMind, or have they already won? And they clearly haven't. Yeah, like, I think there's a lot of-- it's always easy to kind of count yourself out as the startup. But startups keep doing their thing. Well, nobody's counting you out. So guess that's a good thing. I guess so.
The one and only person who's gonna be deciding our futures. - I don't think so.  - So you have been everywhere in the last few months. - That was a long trip, yeah. It's like a very special experience to just go talk to people that are like users, developers, also world leaders, and just say, "I like all day, every day for so long." - In the middle of all this, you signed a 22 word statement. - Warning about the dangers of AI.
- Mitigating the risk of extinction from AI should be a global priority alongside other societal scale risks such as pandemics and nuclear war. Connect the dots for us here. How do we get from a cool chatbot to the end of humanity? - Well, we're planning not to. - That's the hope. - Like, you know, that's-- - But there's also the fear. - I mean, I think there's many ways it could go wrong, but we work with powerful people.
technology that can be used in dangerous ways very frequently in the world. And I think we've developed over the decades good safety system practices in many categories. It's not perfect and this won't be perfect either. Things will go wrong. The main thing that I feel is important about this technology is that we are on an exponential curve and a relatively steep one. human intuition for exponential curves is like.
like really bad in general. It clearly was not that important in our evolutionary history. And so I think we have to-- given that we all have that weakness, I think we have to really push ourselves to say, OK, GPT4-- not a risk like you're talking about there, but how sure we that GPT9 won't be. And if it might be, even if there's a small percentage chance of it being really bad, that deserves great care. And if there is that small percentage chance, Why keep doing this at all? Like why not stop?
I mean, a bunch of reasons. I think it's-- A, I think that the upsides here are tremendous. Opportunity for everyone on Earth to have a better quality education than basically anyone can get today. That seems really important, and that be a bad thing to stop. Medical care. And what's, I think, going to happen there and making that available, truly globally, that's going to be transformative. The scientific progress we're going to see. I'm a big believer that like...
real sustainable improvements in quality of life come from scientific and technological progress. And I think we're going to have a lot more of that. So they're all the obvious benefits. And you know, like, I think it'd be good to end poverty. But we got to manage through the risk to get there. I also think, at this point, given how much people see the economic benefits and potential, no company could stop it. I think even you would acknowledge You have an incredible amount of power.
at this moment in time. Why should we trust you? - You shouldn't. Like, you know, I don't, as you know me for a long time, public talking, I'd rather be in the office working. But I think at this moment in time, like people deserve basically as much time asking questions as they want. And I'm trying to show up and do it. But more to that, Alright.
Like no one person should be trusted here. The board can fire me, I think that's important. I think the board over time needs to get like, democratized to all of humanity. There's many ways that could be implemented. When we think this technology, the benefits, the access to it, the governance of it, the long-steam entity as a whole. If this really works, it's like quite a powerful technology. You should not trust one company and certainly not one person with it.
