Design a fake news detection system. Okay, sounds good. So, I'm going to talk a little bit about my assumptions about this system. I will assume that we will be designing a fake news detection system for social media, because increasingly news are read mostly through social networks. Although some of the components of the system I'm going to talk about are applicable to pure text applications that don't have any social network information. I will also assume that we have access to information about the social network, so users, user follow accounts, how the information flows through the network, like posts, timing of the posts, etc., etc. So, I will share my screen and show you a diagram of the fake news detection system. So, we're going to have a few modules in this fake news detection system. We are going to assume that we have an incoming media post. This is going to be our input, and our output is going to be whether it's fake or real, and there's going to be obviously some action taken depending on that. In the beginning, we want to classify whether this is news or not news, because if we stick a label of fake on someone's opinion, we might have some problems arising from that. So, we will have some attributes that come together with the social media post, so basically we determine whether it's not news, then whether it has a URL or not URL, and then we have the user characteristics, so maybe number of followers, connections, other posts, etc. And then we will have three different modules where this social media post will go into. The first one is a text analysis module. The second one will analyze the URL, if it exists, and the third one will analyze the movement of the post through the network. So, the text analysis module will do two things. It will have a model for analyzing just the text, and there are some features that might give out a fake news post. For example, it might be very subjective. It might have a lot of question marks, some quantifiers, generalizations, and that kind of analysis is good, but it's probably not very reliable, because as we know, even people are very bad at determining whether a news piece is fake or real, so the machine probably will not be either. So, to support that, we will have another part of this module where we represent each fact as an RDF triple. So, this is just saying, for instance, we have a sentence, John saw the cat. So, we represent that as a triple where the subject is John, the predicate is saw, and the object is the cat. And we take more complex sentences and we'll represent each pairing of subject and object with the predicate as a triple. And then, basically, for this one to work, we need an outside knowledge base, such as DBpedia, because then we match these facts to DBpedia. And then, recent research has found that the more concrete those entities and those facts and those triples are, the better the chance that the news piece is real, because if it's very general, then it's easy to go either way. You can be talking about something very confidently, but it's just talk. So, combining these two things, and there are different options for combining these, right? We could train two different models, one for the text alone, one for the facts of triples. We could combine the two and use embeddings and concatenate, for example, the embeddings. Or we could have a voting system. There are many different options for this. And if I did voting, I would put less weight on the text only and more weight on the fact as triples analysis, because it's also supported by an outside source that we know is verified. Got it. So, this will output whether fake or real, and we will have some confidence marker. And if it's high confidence, then probably we will want to take immediate action if it's definitely a fake news item. But if it's low confidence, then we will defer to our third module, which I'll talk about later. So, the second module will take the URL. It will take the URL. It will read the URL. And then it will take the title of the text and the text itself. And also the URL. Is this a URL of the actual post itself, or is this a URL contained within the post? Yeah, sorry. I should have been more clear. It's the URL that's contained in the post. Got it. Okay. So, we take the supporting URL for the social media post, and then we take the title and we take the text. And again, recent research has found that if the title and the text agree, then it's more likely to be a real news item. But if they don't agree, then probably it's either fake or misleading. Because the headline can say one thing, but the actual text is not saying that. So, that's called stance detection. And then we will do that using this module. And then we will do the same thing. And I'm actually thinking that probably these three, so text, just text, faxes, ripples, and URL, could be combined into one module that will say whether it's fake or real. Okay. So, if it's high confidence, take action. If it's low confidence, we go on to the network analysis module. And why… Quick question. Yes. So, if these two could be combined into one, are there any advantages to separating them into two separate modules? Yes, because some posts will not contain a URL. So… Ah, that's fair. Okay. But we can, you know, there are probably ways around that. So, but yeah. That's fair. And the reason why we have the network analysis module that's kind of to the side and we only use it with low confidence scores is because it can only work if it's delayed in time. Because it is analyzing the movement of the post through the network. Basically, how the users are posting, which users are posting, et cetera, et cetera. So, about in the recent research that I read, it said about two hours is the time that needs to pass before this module can work correctly and identify whether the item is real or fake. And we will need a model here as well that takes in, apart from the actual post and the user information of the post, the user who posted the item, we need the representation of the social network as a graph database. And obviously, we will need to partition it because we cannot probably put in the whole thing in there. Yeah. And what are, yeah, if you're touching on this, I apologize. What are some of the characteristics that a fake news post would demonstrate in its movement in the network versus real news? So, I think it might be different which users are posting it and how quickly it's appearing through the network. Because some people might be copy pasting, you know, if it's like robots, it's moving very fast, but it might be real people who are disseminating it, for example. Okay. So, that's one characteristic, for example. Yeah. So, here, I think if we take the combination of all these and it says it's fake, then we have a lot more confidence that it's really fake. So, take some action based on this output. Okay. So, the two external data sources that we will need are the knowledge base that is put in for the facts analysis and the representation of the social network. And we will need machine learning models. Yeah. And these two will need to be updated frequently as, you know, the facts change quickly and then social network changes. And how frequently that will need to be decided, you know, depending on the business requirements, I would say daily, but maybe even more frequent than that. I don't know. Okay. That's fair. Yeah. And then these will require machine learning models. And to train such machine learning models, we will obviously need some training data. And there are data sets out there that are available for training. For instance, there is the liar data set that's about 13,000 short statements, which is fake or real, just text. And then there is also FNC1, which is about 75,000 labeled headlines and articles. So, this would be for the standards detection, the correspondence between headline and documents. Yeah. And then once this system, we put it into production, we will definitely need to have some quality assurance that it's working as expected and I'm expecting that we would need to do daily checks of all three models or four, depending on how you count here. Daily checks on all three models to evaluate whether they're actually doing their jobs and how accurately they're giving us the answers? Yes, correct. Or how often they're giving us the right answer, rather? Yeah, just measuring, you know, precision and recall. And those metrics will also depend, like which metrics we optimize for will depend whether this system is completely automated or if there is a human in the loop, right? If there's a human in the loop, we can have high recall and precision can be a little less because we want to cover all the cases and the human can hopefully sort through the rest. Yeah, yeah. Okay, that's fair. And what do you do in the situations where, let's say, you get a lot of false positives for fake news? What is the approach in this system to be able to deal with sorting those false positives ultimately? Well, I think the first thing is to do some error analysis just to figure out what happened, why are we having so many false positives. Maybe people are talking about this one particular topic that's being labeled as false positive, and then we need to update the model somehow to make sure that they are not going through as fake when they're actually real. Got it, okay. I'm interested in your perspective on if you were approaching this from the bad actor standpoint, what are some ways that someone could break this system or take advantage of it? Interesting. I guess that's a good way to make sure that it actually works. Well, I think a lot of social media users, they figure out very quickly how the algorithm works and they try to game the system. Even I know on LinkedIn, if you post a post with a link, it will never reach any kind of viewership. It's going to be very low. So people post links in the comments. Same thing. People figure out, oh, the URLs are not going through. I'm just going to put it in the comments. Yeah, this is something that's kind of a cat and mouse game where we try to build a system that will protect us from bad actors, and the bad actors figure it out. Now we have to go back and do something else. Yeah, that's fair. This is a great start to building this kind of system. Thank you so much, Zhenya. I'm wondering, do you have any thoughts on if someone encounters a question like this in the wild, what are your suggestions for how to approach it? Because it's a pretty broad question, and you could go in so many different directions for it. So what are your thoughts on that? Well, I think when you think of any kind of project like this where there is NLP or machine learning involved, think about the business requirements and how they translate into what you need to do and how you find the training data, whether the training data will correspond to what's out there. Because, for instance, the data sets that are public, they go stale very quickly. They might be very curated while your data is going to be wildly different. So maybe a data set that's out there is good for proof of value, but then you will need to collect your own. How are you going to collect your own data? And then after you make the models and they seem to work, how are you going to monitor them and make sure that they don't fail on you, especially silently? Yeah, lovely. Thank you so much, Zhenya. Any final thoughts before we wrap up? Thank you. I enjoyed answering the question and hope you enjoyed watching it. Yeah, absolutely. I learned something during this. It's not my area of expertise, but I really enjoyed learning about, yeah, I would build a system like this for a very, very tough and pertinent problem today. So thank you so much. And I hope this is valuable for everyone at home. Good luck with your interviews. Thanks so much for watching. Don't forget to hit the like and subscribe buttons below to let us know that this video is valuable for you. And, of course, check out hundreds more videos just like this at TriExponent.com. Thanks for watching and good luck on your upcoming interview. Transcription by ESO. Translation by —